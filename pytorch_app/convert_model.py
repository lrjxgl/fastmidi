"""
PaddlePaddle æ¨¡å‹è½¬ PyTorch æ¨¡å‹è½¬æ¢è„šæœ¬
å°† PaddlePaddle è®­ç»ƒçš„æ¨¡å‹æƒé‡è½¬æ¢ä¸º PyTorch æ ¼å¼
"""

import os
import sys

import torch
import paddle
import argparse
from collections import OrderedDict

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config


def convert_paddle_to_torch(paddle_path: str, torch_path: str, config: Config):
    """å°† PaddlePaddle æ¨¡å‹è½¬æ¢ä¸º PyTorch æ¨¡å‹"""
    
    print("=" * 60)
    print("ğŸ”„ PaddlePaddle â†’ PyTorch æ¨¡å‹è½¬æ¢")
    print("=" * 60)
    
    print(f"\nğŸ“‚ åŠ è½½ PaddlePaddle æ¨¡å‹: {paddle_path}")
    
    paddleCheckpoint = paddle.load(paddle_path)
    
    if isinstance(paddleCheckpoint, dict):
        if 'model_state_dict' in paddleCheckpoint:
            paddle_state_dict = paddleCheckpoint['model_state_dict']
            print(f"   âœ“ ä» model_state_dict æå–æ¨¡å‹å‚æ•°")
        else:
            paddle_state_dict = paddleCheckpoint
    else:
        paddle_state_dict = paddleCheckpoint
    
    model_config = config.MODEL_CONFIG
    
    print(f"\nğŸ“Š æ¨¡å‹é…ç½®:")
    print(f"   - d_model: {model_config['d_model']}")
    print(f"   - d_state: {model_config['d_state']}")
    print(f"   - n_layers: {model_config['n_layers']}")
    print(f"   - vocab_size: {model_config['vocab_size']}")
    
    print(f"\nğŸ” PaddlePaddle æ¨¡å‹å‚æ•°åˆ—è¡¨:")
    tensor_count = 0
    for name, param in paddle_state_dict.items():
        if hasattr(param, 'shape'):
            print(f"   {name}: shape={param.shape}, dtype={param.dtype}")
            tensor_count += 1
    
    print(f"\n   æ€»è®¡: {tensor_count} ä¸ªå¼ é‡å‚æ•°")
    
    print(f"\nğŸ”„ å¼€å§‹è½¬æ¢å‚æ•° (PaddlePaddle â†’ PyTorch)...")
    print(f"   æ³¨æ„: PaddlePaddle å’Œ PyTorch çš„ Linear å±‚æƒé‡å½¢çŠ¶æ˜¯è½¬ç½®å…³ç³»")
    
    torch_state_dict = OrderedDict()
    converted_count = 0
    transposed_count = 0
    
    for paddle_name, param in paddle_state_dict.items():
        if hasattr(param, 'shape'):
            param_numpy = param.numpy()
            
            torch_name = paddle_name
            
            need_transpose = False
            if param_numpy.ndim == 2:
                if 'proj' in paddle_name and 'embedding' not in paddle_name:
                    need_transpose = True
                elif 'bpm_embedding' in paddle_name and 'weight' in paddle_name:
                    need_transpose = True
            
            if need_transpose:
                param_numpy = param_numpy.T
                transposed_count += 1
            
            torch_state_dict[torch_name] = torch.from_numpy(param_numpy)
            print(f"   âœ“ {paddle_name}" + (" (è½¬ç½®)" if need_transpose else ""))
            converted_count += 1
    
    print(f"\nğŸ“Š è½¬æ¢ç»Ÿè®¡:")
    print(f"   - æˆåŠŸè½¬æ¢: {converted_count}")
    print(f"   - è½¬ç½®æ“ä½œ: {transposed_count}")
    
    print(f"\nğŸ’¾ ä¿å­˜ PyTorch æ¨¡å‹: {torch_path}")
    os.makedirs(os.path.dirname(torch_path), exist_ok=True)
    torch.save({
        'model_state_dict': torch_state_dict,
        'config': {
            'd_model': config.MODEL_CONFIG['d_model'],
            'd_state': config.MODEL_CONFIG['d_state'],
            'd_conv': config.MODEL_CONFIG['d_conv'],
            'expand': config.MODEL_CONFIG['expand'],
            'n_layers': config.MODEL_CONFIG['n_layers'],
            'dropout': config.MODEL_CONFIG['dropout'],
            'max_seq_length': config.MODEL_CONFIG['max_seq_length'],
            'vocab_size': config.MODEL_CONFIG['vocab_size'],
        }
    }, torch_path)
    
    print(f"\nâœ… è½¬æ¢å®Œæˆ!")
    print(f"   PyTorch æ¨¡å‹å·²ä¿å­˜åˆ°: {torch_path}")
    
    return torch_state_dict


def load_torch_model(torch_path: str, config: Config):
    """åŠ è½½ PyTorch æ¨¡å‹å¹¶è¿”å›çŠ¶æ€å­—å…¸"""
    print(f"\nğŸ“‚ åŠ è½½ PyTorch æ¨¡å‹: {torch_path}")
    
    checkpoint = torch.load(torch_path, map_location='cpu')
    
    print(f"   æ¨¡å‹é…ç½®: {checkpoint.get('config', 'N/A')}")
    
    return checkpoint['model_state_dict']


def verify_conversion(paddle_path: str, torch_state_dict: dict):
    """éªŒè¯è½¬æ¢ç»“æœ"""
    print(f"\nğŸ” éªŒè¯è½¬æ¢ç»“æœ...")
    
    paddleCheckpoint = paddle.load(paddle_path)
    
    if isinstance(paddleCheckpoint, dict) and 'model_state_dict' in paddleCheckpoint:
        paddle_state_dict = paddleCheckpoint['model_state_dict']
    else:
        paddle_state_dict = paddleCheckpoint
    
    verified_count = 0
    for name, torch_param in torch_state_dict.items():
        if name in paddle_state_dict:
            paddle_param = paddle_state_dict[name]
            if hasattr(paddle_param, 'numpy'):
                paddle_param = paddle_param.numpy()
                
                param_numpy = paddle_param
                if torch_param.ndim == 2:
                    param_numpy = param_numpy.T
                
                diff = float(torch.abs(torch.from_numpy(param_numpy) - torch_param).max())
                print(f"   âœ“ {name}: max_diff={diff:.8f}")
                verified_count += 1
    
    print(f"\n   éªŒè¯é€šè¿‡: {verified_count}/{len(torch_state_dict)} ä¸ªå‚æ•°")


def main():
    parser = argparse.ArgumentParser(description='PaddlePaddle æ¨¡å‹è½¬ PyTorch')
    parser.add_argument('--paddle-model', type=str, 
                       default='../work/checkpoints/best_model.pdparams',
                       help='PaddlePaddle æ¨¡å‹è·¯å¾„')
    parser.add_argument('--torch-model', type=str, 
                       default='models/best_model.pt',
                       help='PyTorch æ¨¡å‹è¾“å‡ºè·¯å¾„')
    parser.add_argument('--verify', action='store_true',
                       help='éªŒè¯è½¬æ¢ç»“æœ')
    args = parser.parse_args()
    
    config = Config()
    
    paddle_path = os.path.abspath(os.path.join(os.path.dirname(__file__), args.paddle_model))
    torch_path = os.path.abspath(os.path.join(os.path.dirname(__file__), args.torch_model))
    
    torch_state_dict = convert_paddle_to_torch(paddle_path, torch_path, config)
    
    if args.verify:
        verify_conversion(paddle_path, torch_state_dict)
    
    print("\n" + "=" * 60)
    print("ğŸ“ ä½¿ç”¨æ–¹æ³•:")
    print("=" * 60)
    print("""
1. è½¬æ¢æ¨¡å‹:
   python convert_model.py

2. éªŒè¯è½¬æ¢:
   python convert_model.py --verify

3. åœ¨æ¨ç†åº”ç”¨ä¸­ä½¿ç”¨:
   from mamba_model import MambaMIDIGenerator, create_model
   import torch
   
   model = create_model(config)
   checkpoint = torch.load('models/best_model.pt', map_location='cpu')
   model.load_state_dict(checkpoint['model_state_dict'])
   model.eval()
    """)


if __name__ == '__main__':
    main()
