"""
PyTorch MIDI éŸ³ä¹ç”Ÿæˆæ¨ç†åº”ç”¨
åŸºäº PaddlePaddle è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†
"""

import os
import sys
import torch
import gradio as gr
from typing import Dict, Optional, List
from datetime import datetime

from config import Config
from midi_processor import MIDIProcessor
from mamba_model import MambaMIDIGenerator, create_model
from audio_synthesizer import AudioSynthesizer


class MIDIGeneratorUI:
    def __init__(self, config: Config, model_path: Optional[str] = None):
        self.config = config
        self.processor = MIDIProcessor(config)
        self.synthesizer = AudioSynthesizer(config)
        
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            print(f'Using GPU: {torch.cuda.device_count()} device(s) available')
        else:
            self.device = torch.device('cpu')
            print('Using CPU')
        
        self.model = self._load_model(model_path)
        
        self.output_dir = os.path.join(config.PROCESSED_DATA_DIR, 'generated')
        os.makedirs(self.output_dir, exist_ok=True)
    
    def _load_model(self, model_path: Optional[str]) -> MambaMIDIGenerator:
        model = create_model(self.config)
        
        if model_path and os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device)
            model_state = checkpoint['model_state_dict']
            
            new_state_dict = {}
            for key, value in model_state.items():
                new_key = key.replace('mamba.', 'mamba.', 1)
                new_state_dict[new_key] = value
            
            model.load_state_dict(new_state_dict, strict=False)
            print(f'Loaded model from {model_path}')
        else:
            print('Using untrained model')
        
        model.to(self.device)
        model.eval()
        
        return model
    
    def generate_midi(self, emotion: str, style: str, key: str, mode: str,
                      bpm: int, bars: int, instruments: List[str],
                      temperature: float, top_k: int, top_p: float,
                      verbose: bool = True) -> tuple:
        try:
            import random
            import time
            
            print("\n" + "=" * 60)
            print("ğŸµ å¼€å§‹ç”ŸæˆéŸ³ä¹ (PyTorch)...")
            print("=" * 60)
            print(f"ğŸ“Š å‚æ•°: æƒ…ç»ª={emotion}, é£æ ¼={style}, è°ƒæ€§={key}{mode}, BPM={bpm}, å°èŠ‚æ•°={bars}, ä¹å™¨={instruments}")
            
            seed = random.randint(0, 2**32 - 1)
            print(f"ğŸ² éšæœºç§å­: {seed}")
            
            emotion_idx = self.processor.emotion_to_idx[emotion]
            style_idx = self.processor.style_to_idx[style]
            key_idx = self.processor.key_to_idx[key]
            mode_idx = self.processor.mode_to_idx[mode]
            
            beats_per_bar = 4
            total_beats = bars * beats_per_bar
            
            avg_note_beats = 0.5
            safety_factor = 3.0
            estimated_notes = int(total_beats / avg_note_beats * safety_factor)
            max_length = min(estimated_notes, self.config.MODEL_CONFIG['max_seq_length'])
            
            print(f"ğŸ“ ç›®æ ‡: {bars}å°èŠ‚ Ã— {beats_per_bar}æ‹ = {total_beats}æ‹")
            print(f"ğŸ“ é¢„ä¼°éŸ³ç¬¦æ•°: ~{estimated_notes}ä¸ª, ç”Ÿæˆé•¿åº¦: {max_length} tokens")
            
            num_tracks = len(instruments)
            print(f"ğŸ¼ éŸ³è½¨æ•°: {num_tracks}")
            
            status_messages = []
            status_messages.append(f"ğŸµ å¼€å§‹ç”ŸæˆéŸ³ä¹ (PyTorch)...")
            status_messages.append(f"ğŸ“Š å‚æ•°: æƒ…ç»ª={emotion}, é£æ ¼={style}, è°ƒæ€§={key}{mode}, BPM={bpm}, å°èŠ‚æ•°={bars}, ä¹å™¨={instruments}")
            status_messages.append(f"ğŸ² éšæœºç§å­: {seed}")
            status_messages.append(f"ğŸ“ ç›®æ ‡: {bars}å°èŠ‚ Ã— {beats_per_bar}æ‹ = {total_beats}æ‹, é¢„ä¼°{estimated_notes}ä¸ªéŸ³ç¬¦")
            status_messages.append(f"ğŸ¼ éŸ³è½¨æ•°: {num_tracks}")
            
            with torch.no_grad():
                print(f"\nğŸ”„ [1/4] å¼€å§‹ç”Ÿæˆtokens...")
                token_start_time = time.time()
                
                if num_tracks > 1:
                    tokens_dict = self.model.generate_multi_track(
                        emotion=emotion_idx,
                        style=style_idx,
                        key=key_idx,
                        mode=mode_idx,
                        bpm=bpm,
                        num_tracks=num_tracks,
                        max_length=max_length,
                        temperature=temperature,
                        top_k=top_k,
                        top_p=top_p,
                        seed=seed
                    )
                    
                    total_tokens = sum(len(tokens) for tokens in tokens_dict.values())
                    token_time = time.time() - token_start_time
                    print(f"âœ… Tokenç”Ÿæˆå®Œæˆ!")
                    print(f"   - ç”Ÿæˆæ—¶é—´: {token_time:.2f}ç§’")
                    print(f"   - æ€»tokensæ•°: {total_tokens}")
                    print(f"   - ç”Ÿæˆé€Ÿåº¦: {total_tokens/token_time:.1f} tokens/ç§’")
                    
                    status_messages.append(f"\nğŸ”„ [1/4] Tokenç”Ÿæˆå®Œæˆ: {token_time:.2f}ç§’, {total_tokens} tokens, {total_tokens/token_time:.1f} tokens/ç§’")
                    
                    print(f"\nğŸ”„ [2/4] å¼€å§‹å¤„ç†å¤šéŸ³è½¨MIDI...")
                    midi_start_time = time.time()
                    
                    track_tokens = {}
                    all_single_notes = 0
                    all_chord_starts = 0
                    all_chord_notes = 0
                    
                    for i, (track_id, tokens) in enumerate(tokens_dict.items()):
                        instrument_idx = self.processor.instrument_to_idx[instruments[i]]
                        track_tokens[instrument_idx] = tokens.tolist()
                        
                        chord_start_token_start = self.processor.chord_start_token_start
                        chord_note_token_start = self.processor.chord_note_token_start
                        
                        single_notes = sum(1 for t in tokens if t < chord_start_token_start)
                        chord_starts = sum(1 for t in tokens if chord_start_token_start <= t < chord_note_token_start)
                        chord_note_tokens = sum(1 for t in tokens if t >= chord_note_token_start)
                        
                        all_single_notes += single_notes
                        all_chord_starts += chord_starts
                        all_chord_notes += chord_note_tokens
                        
                        print(f"   - éŸ³è½¨{i+1}: {len(tokens)} tokens (å•éŸ³:{single_notes}, å’Œå¼¦å¼€å§‹:{chord_starts}, å’Œå¼¦éŸ³ç¬¦:{chord_note_tokens})")
                    
                    print(f"\n   === Token åˆ†å¸ƒç»Ÿè®¡ ===")
                    print(f"   - å•éŸ³token: {all_single_notes} ({all_single_notes/total_tokens*100:.1f}%)")
                    print(f"   - å’Œå¼¦å¼€å§‹token: {all_chord_starts} ({all_chord_starts/total_tokens*100:.1f}%)")
                    print(f"   - å’Œå¼¦éŸ³ç¬¦token: {all_chord_notes} ({all_chord_notes/total_tokens*100:.1f}%)")
                    print(f"   - ç†è®ºéŸ³ç¬¦æ•°: {all_single_notes + all_chord_notes}")
                    
                    midi = self.processor.tokens_to_multi_track_midi(track_tokens, tempo=float(bpm), max_bars=bars)
                    midi_time = time.time() - midi_start_time
                    print(f"âœ… MIDIå¤„ç†å®Œæˆ!")
                    print(f"   - å¤„ç†æ—¶é—´: {midi_time:.2f}ç§’")
                    print(f"   - éŸ³è½¨æ•°: {len(midi.instruments)}")
                    
                    for idx, inst in enumerate(midi.instruments):
                        instrument_name = self.processor.idx_to_instrument.get(inst.program, f'Track {idx}')
                        print(f"   - éŸ³è½¨{idx+1} ({instrument_name}): {len(inst.notes)} éŸ³ç¬¦")
                    
                    status_messages.append(f"ğŸ”„ [2/4] MIDIå¤„ç†å®Œæˆ: {midi_time:.2f}ç§’, {len(midi.instruments)}éŸ³è½¨")
                else:
                    instrument_idx = self.processor.instrument_to_idx[instruments[0]]
                    
                    tokens = self.model.generate(
                        emotion=emotion_idx,
                        style=style_idx,
                        key=key_idx,
                        mode=mode_idx,
                        bpm=bpm,
                        max_length=max_length,
                        temperature=temperature,
                        top_k=top_k,
                        top_p=top_p,
                        seed=seed
                    )
                    
                    token_time = time.time() - token_start_time
                    print(f"âœ… Tokenç”Ÿæˆå®Œæˆ!")
                    print(f"   - ç”Ÿæˆæ—¶é—´: {token_time:.2f}ç§’")
                    print(f"   - tokensæ•°: {len(tokens)}")
                    print(f"   - ç”Ÿæˆé€Ÿåº¦: {len(tokens)/token_time:.1f} tokens/ç§’")
                    
                    status_messages.append(f"\nğŸ”„ [1/4] Tokenç”Ÿæˆå®Œæˆ: {token_time:.2f}ç§’, {len(tokens)} tokens, {len(tokens)/token_time:.1f} tokens/ç§’")
                    
                    print(f"\nğŸ”„ [2/4] å¼€å§‹å¤„ç†MIDI...")
                    midi_start_time = time.time()
                    
                    tokens = tokens.tolist()
                    
                    chord_start_token_start = self.processor.chord_start_token_start
                    chord_note_token_start = self.processor.chord_note_token_start
                    
                    single_note_count = sum(1 for t in tokens if t < chord_start_token_start)
                    chord_count = sum(1 for t in tokens if chord_start_token_start <= t < chord_note_token_start)
                    chord_note_count = sum(1 for t in tokens if t >= chord_note_token_start)
                    
                    print(f"   - å•éŸ³token: {single_note_count}")
                    print(f"   - å’Œå¼¦å¼€å§‹token: {chord_count}")
                    print(f"   - å’Œå¼¦éŸ³ç¬¦token: {chord_note_count}")
                    
                    if verbose:
                        print(f"\n   å‰20ä¸ªtoken: {tokens[:20]}")
                        print(f"   Tokenç±»å‹åˆ†å¸ƒ:")
                        for i, t in enumerate(tokens[:30]):
                            if t < chord_start_token_start:
                                note_idx = t // self.processor.num_durations
                                dur_idx = t % self.processor.num_durations
                                print(f"     [{i}] {t}: å•éŸ³ note={note_idx+self.processor.min_note} ({self.processor._idx_to_duration_type(dur_idx)})")
                            elif t < chord_note_token_start:
                                dur_idx = t - chord_start_token_start
                                print(f"     [{i}] {t}: å’Œå¼¦å¼€å§‹ ({self.processor._idx_to_duration_type(dur_idx)})")
                            else:
                                pitch = t - chord_note_token_start + self.processor.min_note
                                print(f"     [{i}] {t}: å’Œå¼¦éŸ³ç¬¦ pitch={pitch}")
                    
                    midi = self.processor.tokens_to_midi(tokens, instrument_program=instrument_idx, tempo=float(bpm), max_bars=bars)
                    
                    midi_time = time.time() - midi_start_time
                    note_count = sum(len(inst.notes) for inst in midi.instruments)
                    print(f"âœ… MIDIå¤„ç†å®Œæˆ!")
                    print(f"   - å¤„ç†æ—¶é—´: {midi_time:.2f}ç§’")
                    print(f"   - éŸ³è½¨æ•°: {len(midi.instruments)}")
                    
                    for idx, inst in enumerate(midi.instruments):
                        instrument_name = self.processor.idx_to_instrument.get(inst.program, f'Track {idx}')
                        print(f"   - éŸ³è½¨{idx+1} ({instrument_name}): {len(inst.notes)} éŸ³ç¬¦")
                    
                    status_messages.append(f"ğŸ”„ [2/4] MIDIå¤„ç†å®Œæˆ: {midi_time:.2f}ç§’, {len(midi.instruments)}éŸ³è½¨")
            
            print(f"\nğŸ”„ [3/4] å¼€å§‹ä¿å­˜MIDIæ–‡ä»¶...")
            save_start_time = time.time()
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            midi_filename = f'generated_{timestamp}.mid'
            midi_path = os.path.join(self.output_dir, midi_filename)
            
            self.processor.save_midi(midi, midi_path)
            
            save_time = time.time() - save_start_time
            print(f"âœ… MIDIæ–‡ä»¶ä¿å­˜å®Œæˆ!")
            print(f"   - ä¿å­˜æ—¶é—´: {save_time:.2f}ç§’")
            print(f"   - æ–‡ä»¶è·¯å¾„: {midi_path}")
            
            status_messages.append(f"ğŸ”„ [3/4] MIDIæ–‡ä»¶ä¿å­˜å®Œæˆ: {save_time:.2f}ç§’")
            
            print(f"\nğŸ”„ [4/4] å¼€å§‹åˆæˆWAVéŸ³é¢‘...")
            wav_start_time = time.time()
            
            wav_filename = midi_filename.replace('.mid', '.wav')
            wav_path = os.path.join(self.output_dir, wav_filename)
            
            success = self._synthesize_wav(midi_path, wav_path)
            
            wav_time = time.time() - wav_start_time
            total_time = token_time + midi_time + save_time + wav_time
            
            if success:
                print(f"âœ… WAVåˆæˆå®Œæˆ!")
                print(f"   - åˆæˆæ—¶é—´: {wav_time:.2f}ç§’")
                print(f"   - æ–‡ä»¶è·¯å¾„: {wav_path}")
                print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
                print("=" * 60 + "\n")
                
                status_messages.append(f"ğŸ”„ [4/4] WAVåˆæˆå®Œæˆ: {wav_time:.2f}ç§’")
                status_messages.append(f"ğŸ‰ å…¨éƒ¨å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
                
                instruments_str = ', '.join(instruments)
                final_message = '\n'.join(status_messages)
                return midi_path, wav_path, final_message
            else:
                print(f"âŒ WAVåˆæˆå¤±è´¥!")
                print(f"\nâš ï¸ MIDIç”ŸæˆæˆåŠŸï¼Œä½†WAVè½¬æ¢å¤±è´¥")
                print("=" * 60 + "\n")
                
                status_messages.append(f"âš ï¸ MIDIç”ŸæˆæˆåŠŸï¼Œä½†WAVè½¬æ¢å¤±è´¥")
                
                instruments_str = ', '.join(instruments)
                final_message = '\n'.join(status_messages)
                return midi_path, None, final_message
        
        except Exception as e:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            print("=" * 60 + "\n")
            
            error_message = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n\né”™è¯¯è¯¦æƒ…:\n{str(type(e).__name__)}"
            import traceback
            error_message += f"\n\nå †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}"
            return None, None, error_message
    
    def _synthesize_wav(self, midi_path: str, wav_path: str) -> bool:
        """ä½¿ç”¨ AudioSynthesizer åˆæˆ WAV éŸ³é¢‘"""
        return self.synthesizer.midi_to_wav(midi_path, wav_path, sample_rate=44100)
    
    def create_interface(self):
        with gr.Blocks(title="Mamba MIDI éŸ³ä¹ç”Ÿæˆå™¨ (PyTorch)") as interface:
            gr.Markdown("# ğŸµ Mamba MIDI éŸ³ä¹ç”Ÿæˆå™¨ (PyTorch)")
            gr.Markdown("åŸºäº PaddlePaddle è®­ç»ƒæ¨¡å‹çš„ PyTorch æ¨ç†ç‰ˆæœ¬")
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¨ éŸ³ä¹å‚æ•°")
                    
                    emotion_dropdown = gr.Dropdown(
                        choices=self.config.EMOTIONS,
                        value="å¿«ä¹",
                        label="æƒ…ç»ª"
                    )
                    
                    style_dropdown = gr.Dropdown(
                        choices=self.config.STYLES,
                        value="æµè¡Œ",
                        label="é£æ ¼"
                    )
                    
                    with gr.Row():
                        key_dropdown = gr.Dropdown(
                            choices=self.config.KEYS,
                            value="C",
                            label="è°ƒæ€§"
                        )
                        
                        mode_dropdown = gr.Dropdown(
                            choices=self.config.MODES,
                            value="major",
                            label="è°ƒå¼"
                        )
                    
                    bpm_slider = gr.Slider(
                        minimum=60,
                        maximum=180,
                        value=120,
                        step=1,
                        label="BPM (é€Ÿåº¦)"
                    )
                    
                    bars_slider = gr.Slider(
                        minimum=4,
                        maximum=128,
                        value=8,
                        step=1,
                        label="å°èŠ‚æ•°"
                    )
                    
                    gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
                    
                    temperature_slider = gr.Slider(
                        minimum=0.1,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                        label="Temperature (éšæœºæ€§)"
                    )
                    
                    top_k_slider = gr.Slider(
                        minimum=0,
                        maximum=100,
                        value=50,
                        step=5,
                        label="Top-K (é‡‡æ ·èŒƒå›´)"
                    )
                    
                    top_p_slider = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.9,
                        step=0.05,
                        label="Top-P (æ ¸é‡‡æ ·)"
                    )
                    
                    generate_btn = gr.Button("ğŸ¼ ç”ŸæˆéŸ³ä¹", variant="primary", size="lg")
                    
                with gr.Column(scale=1):
                    instruments_checkbox = gr.CheckboxGroup(
                        choices=self.config.INSTRUMENTS,
                        value=["Acoustic Grand Piano"],
                        label="ä¹å™¨ (å¯å¤šé€‰)"
                    )
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“„ è¾“å‡º")
                    
                    midi_output = gr.File(
                        label="MIDI æ–‡ä»¶",
                        file_types=[".mid", ".midi"]
                    )
                    
                    wav_output = gr.Audio(
                        label="WAV éŸ³é¢‘",
                        type="filepath"
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ ç”Ÿæˆä¿¡æ¯")
                    
                    info_text = gr.Textbox(
                        label="ç”Ÿæˆç»“æœ",
                        lines=10,
                        interactive=False
                    )
            
            gr.Markdown("### ğŸ’¡ ä½¿ç”¨è¯´æ˜")
            gr.Markdown("""
            - **æƒ…ç»ª**: é€‰æ‹©æ­Œæ›²çš„æƒ…æ„ŸåŸºè°ƒï¼ˆå¿«ä¹ã€æ‚²ä¼¤ã€æ¿€æ˜‚ã€å¹³é™ï¼‰
            - **é£æ ¼**: é€‰æ‹©éŸ³ä¹é£æ ¼ï¼ˆæµè¡Œã€æ°‘è°£ã€æ‘‡æ»šã€ä¸­å›½é£ã€è¯´å”±ã€R&Bã€èˆæ›²ï¼‰
            - **è°ƒæ€§**: é€‰æ‹©æ­Œæ›²çš„è°ƒï¼ˆCã€C#ã€Dç­‰ï¼‰
            - **è°ƒå¼**: é€‰æ‹©å¤§è°ƒæˆ–å°è°ƒ
            - **BPM**: è®¾ç½®æ¯åˆ†é’ŸèŠ‚æ‹æ•°ï¼Œå½±å“éŸ³ä¹é€Ÿåº¦
            - **å°èŠ‚æ•°**: è®¾ç½®ç”Ÿæˆçš„éŸ³ä¹é•¿åº¦
            - **ä¹å™¨**: å¯å¤šé€‰ä¹å™¨ï¼Œé€‰æ‹©å¤šä¸ªä¹å™¨å°†ç”Ÿæˆå¤šéŸ³è½¨MIDI
            - **Temperature**: æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šéšæœº
            - **Top-K/Top-P**: æ§åˆ¶é‡‡æ ·ç­–ç•¥ï¼Œå½±å“ç”Ÿæˆçš„å¤šæ ·æ€§
            """)
            
            generate_btn.click(
                fn=self.generate_midi,
                inputs=[
                    emotion_dropdown,
                    style_dropdown,
                    key_dropdown,
                    mode_dropdown,
                    bpm_slider,
                    bars_slider,
                    instruments_checkbox,
                    temperature_slider,
                    top_k_slider,
                    top_p_slider
                ],
                outputs=[midi_output, wav_output, info_text]
            )
        
        return interface
    
    def launch(self, share: bool = False, server_port: int = 7865):
        interface = self.create_interface()
        interface.launch(share=share, server_port=server_port)


def main():
    config = Config()
    
    print("=" * 60)
    print("Mamba MIDI éŸ³ä¹ç”Ÿæˆå™¨ (PyTorch)")
    print("=" * 60)
    print(f"\nè®¾å¤‡: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")
    print(f"è¾“å‡ºç›®å½•: {os.path.join(config.PROCESSED_DATA_DIR, 'generated')}")
    
    paddle_model_path = os.path.join('..', 'work', 'checkpoints', 'best_model.pdparams')
    torch_model_path = os.path.join('models', 'best_model.pt')
    
    if os.path.exists(torch_model_path):
        print(f"åŠ è½½ PyTorch æ¨¡å‹: {torch_model_path}")
        model_path = torch_model_path
    elif os.path.exists(paddle_model_path):
        print(f"éœ€è¦å…ˆè½¬æ¢æ¨¡å‹: {paddle_model_path}")
        print(f"è¿è¡Œ: python convert_model.py")
        model_path = None
    else:
        print("æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹")
        print("è¯·å…ˆè¿è¡Œ PaddlePaddle ç‰ˆæœ¬çš„ train.py è®­ç»ƒæ¨¡å‹")
        model_path = None
    
    print("\nå¯åŠ¨Gradioç•Œé¢...")
    
    app = MIDIGeneratorUI(config, model_path)
    app.launch(server_port=7865)


if __name__ == '__main__':
    main()
